{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Yash Ajay Tapadiya : EX4"
      ],
      "metadata": {
        "id": "1e9yHAB7LF5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D8w60ztJCZpS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import email\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the content in notebook, Spam and Ham emails\n",
        "def load_emails(directory):\n",
        "    emails = []\n",
        "    for filename in os.listdir(directory):\n",
        "        path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(path):\n",
        "            with open(path, \"rb\") as f:\n",
        "                msg = email.message_from_binary_file(f)\n",
        "                payload = \"\"\n",
        "                if msg.is_multipart():\n",
        "                    for part in msg.walk():\n",
        "                        if part.get_content_type() == \"text/plain\":\n",
        "                            payload += part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                else:\n",
        "                    payload = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                emails.append(payload)\n",
        "    return emails\n",
        "\n",
        "spam_emails = load_emails('/content/drive/MyDrive/20021010_spam/spam')\n",
        "ham_emails = load_emails('/content/drive/MyDrive/20021010_easy_ham/easy_ham')\n",
        "\n",
        "X = spam_emails + ham_emails\n",
        "y = [1]*len(spam_emails) + [0]*len(ham_emails)\n",
        "\n",
        "print(\"We have Spam emails:\", len(spam_emails))\n",
        "print(\"We have Ham emails:\", len(ham_emails))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmLpcmFXEJjT",
        "outputId": "0dc85d26-d8e5-4e60-e12e-347d00d0a485"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have Spam emails: 501\n",
            "We have Ham emails: 2551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the data REmoving headers, removing urls, etc\n",
        "def preprocess_email(text,\n",
        "                     lower=True,\n",
        "                     remove_headers=True,\n",
        "                     replace_urls=True,\n",
        "                     replace_numbers=True,\n",
        "                     remove_punctuation=True):\n",
        "\n",
        "    if remove_headers:\n",
        "        text = text.split(\"\\n\\n\", 1)[-1]\n",
        "\n",
        "    if lower:\n",
        "        text = text.lower()\n",
        "\n",
        "    if replace_urls:\n",
        "        text = re.sub(r\"http\\S+|www\\S+\", \" URL \", text)\n",
        "\n",
        "    if replace_numbers:\n",
        "        text = re.sub(r\"\\d+\", \" NUMBER \", text)\n",
        "\n",
        "    if remove_punctuation:\n",
        "        text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "X_cleaned = [preprocess_email(email) for email in X]\n"
      ],
      "metadata": {
        "id": "PiL-7eeEGFFE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data to be used by our models\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_cleaned, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "XCqPsirdGErO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Email to vector\n",
        "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "waX4DAQZGYpL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_nb = nb.predict(X_test_vec)\n",
        "\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(classification_report(y_test, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk04nRiNGYnG",
        "outputId": "1e782f75-f1e3-4586-a025-3c75f98c11fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       511\n",
            "           1       0.97      0.73      0.83       100\n",
            "\n",
            "    accuracy                           0.95       611\n",
            "   macro avg       0.96      0.86      0.90       611\n",
            "weighted avg       0.95      0.95      0.95       611\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test_vec)\n",
        "\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAcYQO2VGYkh",
        "outputId": "2eea094d-eaa7-472e-9f29-3e57c9cc6526"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       511\n",
            "           1       0.99      0.68      0.80       100\n",
            "\n",
            "    accuracy                           0.95       611\n",
            "   macro avg       0.96      0.84      0.89       611\n",
            "weighted avg       0.95      0.95      0.94       611\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_svm = svm.predict(X_test_vec)\n",
        "\n",
        "print(\"SVM Results:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpaExvH-GYiG",
        "outputId": "492dc4f7-3731-4b63-f2f7-7743222975cf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       511\n",
            "           1       0.77      0.91      0.83       100\n",
            "\n",
            "    accuracy                           0.94       611\n",
            "   macro avg       0.88      0.93      0.90       611\n",
            "weighted avg       0.95      0.94      0.94       611\n",
            "\n"
          ]
        }
      ]
    }
  ]
}